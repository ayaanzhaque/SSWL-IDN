{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CT-Denoising-WindowLevel.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zubaerimran/SSWL-IDN/blob/main/SSWL-IDN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoWjvReOWQL2"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-6pj-NaUgpH",
        "outputId": "7f25b0a0-615e-4507-b8c6-e4380062f9b7"
      },
      "source": [
        "  from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wwL48daUaqq",
        "outputId": "3c2302f5-f61f-4c37-80f8-c03ce7cba799"
      },
      "source": [
        "!pip install dicom_numpy\n",
        "!pip install lpips"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: dicom_numpy in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: pydicom in /usr/local/lib/python3.7/dist-packages (from dicom_numpy) (2.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from dicom_numpy) (1.19.5)\n",
            "Requirement already satisfied: lpips in /usr/local/lib/python3.7/dist-packages (0.1.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7xJNm2vUmJt"
      },
      "source": [
        "import os, re\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import dicom_numpy as dcm2np\n",
        "import pydicom as dicom\n",
        "import scipy.io as sio\n",
        "import pdb\n",
        "\n",
        "from skimage.transform import resize\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kjHJevYWTce"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJ8frgk8UpyU"
      },
      "source": [
        "#Returns numpy array and image affine from a list of dicoms\n",
        "def extract_voxel_data(list_of_dicom_files):\n",
        "    datasets = [dicom.read_file(f) for f in list_of_dicom_files]\n",
        "    try:\n",
        "        ndarray, afn = dcm2np.combine_slices(datasets)\n",
        "    except:\n",
        "        print(len(datasets))\n",
        "        pass\n",
        "        #dicom_numpy.DicomImportException as e:\n",
        "        # invalid DICOM data\n",
        "        #raise\n",
        "    for idx in range(ndarray.shape[-1]):\n",
        "        ndarray[:,:,idx] = np.transpose(ndarray[:,:,idx], (1,0)) #transpose to align the axes [from (y, x) to (x, y)]\n",
        "    return ndarray, afn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuFsxDLsUr1l"
      },
      "source": [
        "#Simulate low-dose\n",
        "'''\n",
        "Given: quarter dose and full dose CT images, required Dose level.\n",
        "Return: Images at the Dose level\n",
        "'''\n",
        "def simulate_ld(I_qd, I_fd, Dose=1.):\n",
        "    if Dose==1:\n",
        "        return I_fd\n",
        "    elif Dose==0.25:\n",
        "        return I_qd\n",
        "    else:\n",
        "        a = np.sqrt(((1/Dose)-1)/3)\n",
        "        #print(a)\n",
        "\n",
        "        I_noise = I_qd - I_fd # extract the noise array by just subtracting the images\n",
        "\n",
        "        return I_fd+(a*I_noise) # take the full dose and add the noise multiplied by a coefficient, which is a function inputting the requested dose\n",
        "\n",
        "\n",
        "#Window-leveling\n",
        "'''\n",
        "input (before w/l image, window width, window center, newmax, newmin)\n",
        "'''\n",
        "def window_leveling(x, w, c, ymin=0, ymax=1.):\n",
        "    sh = x.shape\n",
        "\n",
        "    y = np.zeros(sh) #window-leveled image\n",
        "    \n",
        "    #print(x[x >= -110 & x < 189])\n",
        "    #if (x <= c - 0.5 - (w-1) /2), then y = ymin\n",
        "    mask1 = ( x <= (c - 0.5 - (w-1) /2) )\n",
        "    y[mask1] = ymin #Update\n",
        "    \n",
        "    #else if (x > c - 0.5 + (w-1) /2), then y = ymax\n",
        "    mask2 = ( x > (c - 0.5 + (w-1) /2) )\n",
        "    y[mask2] = ymax #Update\n",
        "\n",
        "    #else y = ((x - (c - 0.5)) / (w-1) + 0.5) * (ymax- ymin) + ymin\n",
        "    mask3 = ( x > (c - 0.5 - (w-1) /2)) & (x <= (c - 0.5 + (w-1) /2) ) \n",
        "    np.putmask(y, mask3, ((x - (c - 0.5)) / (w-1) + 0.5) * (ymax- ymin) + ymin) #Update\n",
        "    \n",
        "    return y #return window-leveled image\n",
        "\n",
        "\n",
        "#For each CT slice, do w/l and resizing if required\n",
        "def prep_slices(volume, scale=512):\n",
        "    resized_data = []\n",
        "    \n",
        "    for i in range(volume.shape[0]):\n",
        "        img = window_leveling(volume[i], 300, 40) #width=300, center=40\n",
        "        #print('Img max-min: ', np.max(img), np.min(img))\n",
        "        \n",
        "        #img = resize(img, [scale, scale]) #uncomment for resizing\n",
        "        assert img.shape == (scale, scale)\n",
        "        try:\n",
        "            assert np.max(img) == 1.\n",
        "            assert np.min(img) == 0.\n",
        "        except:\n",
        "            print('Wrong!')\n",
        "        resized_data.append(img)\n",
        "    \n",
        "    resized_data = np.reshape(resized_data, [-1, scale, scale])\n",
        "\n",
        "    return resized_data\n",
        "\n",
        "#For each CT slice, do w/l and resizing if required\n",
        "def prep_slices_no_window_leveling(volume, scale=512):\n",
        "    resized_data = []\n",
        "    \n",
        "    for i in range(volume.shape[0]):\n",
        "        # img = window_leveling(volume[i], 300, 40) #width=300, center=40\n",
        "        img = volume[i]\n",
        "        print('Img max-min: ', np.max(img), np.min(img))\n",
        "\n",
        "        # pdb.set_trace()\n",
        "\n",
        "        #img = resize(img, [scale, scale]) #uncomment for resizing\n",
        "        assert img.shape == (scale, scale)\n",
        "        try:\n",
        "            assert np.max(img) == 1.\n",
        "            assert np.min(img) == 0.\n",
        "        except:\n",
        "            print('Wrong!')\n",
        "        resized_data.append(img)\n",
        "    \n",
        "    resized_data = np.reshape(resized_data, [-1, scale, scale])\n",
        "\n",
        "    return resized_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQEY7-OlXEvr"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uR87Vsq71Eea"
      },
      "source": [
        "ld_train = sio.loadmat(\"/content/drive/MyDrive/Research/SSL_Ayaan/all_ct_data_5dose.mat\")['ld_train']\n",
        "fd_train = sio.loadmat(\"/content/drive/MyDrive/Research/SSL_Ayaan/all_ct_data_5dose.mat\")['fd_train']\n",
        "\n",
        "ld_test = sio.loadmat(\"/content/drive/MyDrive/Research/SSL_Ayaan/all_ct_data_5dose.mat\")['ld_test']\n",
        "fd_test = sio.loadmat(\"/content/drive/MyDrive/Research/SSL_Ayaan/all_ct_data_5dose.mat\")['fd_test']\n",
        "\n",
        "ld_train_nw = sio.loadmat(\"/content/drive/MyDrive/Research/SSL_Ayaan/all_ct_data_nowindow_5dose.mat\")['ld_train_nw']\n",
        "fd_train_nw = sio.loadmat(\"/content/drive/MyDrive/Research/SSL_Ayaan/all_ct_data_nowindow_5dose.mat\")['fd_train_nw']\n",
        "\n",
        "ld_test_nw = sio.loadmat(\"/content/drive/MyDrive/Research/SSL_Ayaan/all_ct_data_nowindow_5dose.mat\")['ld_test_nw']\n",
        "fd_test_nw = sio.loadmat(\"/content/drive/MyDrive/Research/SSL_Ayaan/all_ct_data_nowindow_5dose.mat\")['fd_test_nw']\n",
        "\n",
        "# normalize non-window-leveled scans\n",
        "ld_train_nw = (ld_train_nw - np.min(ld_train_nw))/np.ptp(ld_train_nw)\n",
        "fd_train_nw = (fd_train_nw - np.min(fd_train_nw))/np.ptp(fd_train_nw)\n",
        "ld_test_nw = (ld_test_nw - np.min(ld_test_nw))/np.ptp(ld_test_nw)\n",
        "fd_test_nw = (fd_test_nw - np.min(fd_test_nw))/np.ptp(fd_test_nw)\n",
        "\n",
        "print(ld_train.shape, ld_train.shape)\n",
        "print(ld_test.shape, fd_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MpF4CFhUxzn"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ek0N_pWmU8rb"
      },
      "source": [
        "import torch\n",
        "from torch import nn,optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "import lpips\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from skimage.util import random_noise\n",
        "from sklearn.preprocessing import normalize\n",
        "import skimage.metrics as skmetrics\n",
        "\n",
        "import time\n",
        "from collections import defaultdict\n",
        "from itertools import cycle\n",
        "import gc\n",
        "from math import exp\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.init as init"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "997Ks6sANG4b"
      },
      "source": [
        "class CT_Dataset(Dataset):\n",
        "    def __init__(self, inputs, targets, transform=None):\n",
        "\n",
        "        self.input_ = inputs\n",
        "        self.target_ = targets\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.target_)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_img, target_img = self.input_[idx], self.target_[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            input_img = self.transform(input_img)\n",
        "            target_img = self.transform(target_img)\n",
        "        \n",
        "        \n",
        "        return (input_img, target_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQoq1OT2U3FI"
      },
      "source": [
        "# Define Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXIFYBc_IQN7"
      },
      "source": [
        "class SSWL_IDN(nn.Module):\n",
        "    def __init__(self, img_ch = 1, out_ch=96, latent_dim = 256):\n",
        "        super(VAE_RED_CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(img_ch, out_ch, kernel_size=5, stride=1, padding=0)\n",
        "        self.conv2 = nn.Conv2d(out_ch, out_ch, kernel_size=5, stride=1, padding=0)\n",
        "        self.conv3 = nn.Conv2d(out_ch, out_ch, kernel_size=5, stride=1, padding=0)\n",
        "        self.conv4 = nn.Conv2d(out_ch, out_ch, kernel_size=5, stride=1, padding=0)\n",
        "        self.conv5 = nn.Conv2d(out_ch, out_ch, kernel_size=5, stride=1, padding=0)\n",
        "\n",
        "        # Build Bottleneck\n",
        "        self.fc_mu = nn.Linear(96 * 4 * 4, latent_dim)\n",
        "        self.fc_var = nn.Linear(96 * 4 * 4, latent_dim)\n",
        "\n",
        "        # Build Decoder\n",
        "\n",
        "        self.decoder_input = nn.Linear(latent_dim, 96 * 4 * 4)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((4,4))\n",
        "        self.upsample = nn.Upsample(scale_factor= (256 - 4 * 5)/4, mode='bilinear', align_corners=True)\n",
        "\n",
        "        self.tconv1 = nn.ConvTranspose2d(out_ch, out_ch, kernel_size=5, stride=1, padding=0)\n",
        "        self.tconv2 = nn.ConvTranspose2d(out_ch, out_ch, kernel_size=5, stride=1, padding=0)\n",
        "        self.tconv3 = nn.ConvTranspose2d(out_ch, out_ch, kernel_size=5, stride=1, padding=0)\n",
        "        self.tconv4 = nn.ConvTranspose2d(out_ch, out_ch, kernel_size=5, stride=1, padding=0)\n",
        "        self.tconv5 = nn.ConvTranspose2d(out_ch, img_ch, kernel_size=5, stride=1, padding=0)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # encoder\n",
        "        residual_1 = x\n",
        "        out = self.relu(self.conv1(x))\n",
        "        out = self.relu(self.conv2(out))\n",
        "        residual_2 = out\n",
        "        out = self.relu(self.conv3(out))\n",
        "        out = self.relu(self.conv4(out))\n",
        "        residual_3 = out\n",
        "        out = self.relu(self.conv5(out))\n",
        "\n",
        "        result = self.avgpool(out)\n",
        "        result = torch.flatten(result, start_dim=1)\n",
        "        # Split the result into mu and var components of the latent Gaussian distribution\n",
        "        mu = self.fc_mu(result)\n",
        "        logvar = self.fc_var(result)\n",
        "\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        z = eps * std + mu\n",
        "\n",
        "        result = self.decoder_input(z)\n",
        "        result = result.view(-1, 96, 4, 4)\n",
        "        result = self.upsample(result)\n",
        "\n",
        "        # decoder\n",
        "        out = self.tconv1(result)\n",
        "        out += residual_3\n",
        "        out = self.tconv2(self.relu(out))\n",
        "        out = self.tconv3(self.relu(out))\n",
        "        out += residual_2\n",
        "        out = self.tconv4(self.relu(out))\n",
        "        out = self.tconv5(self.relu(out))\n",
        "        out += residual_1\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out, mu, logvar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VzZd0ndSWWn"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duYWSz2H7h14"
      },
      "source": [
        "## Loops"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTAN2zhPZvYo"
      },
      "source": [
        "def compute_measure(x, y, pred, data_range = None):\n",
        "\n",
        "    original_psnr = compute_PSNR(y, x, data_range)\n",
        "    original_ssim = compute_SSIM(y, x, data_range)\n",
        "    original_mse = compute_MSE(y, x)\n",
        "    original_rmse = compute_RMSE(y, x)\n",
        "    original_nrmse = compute_NRMSE(y, x)\n",
        "\n",
        "    pred_psnr = compute_PSNR(y, pred, data_range)\n",
        "    pred_ssim = compute_SSIM(y, pred, data_range)\n",
        "    pred_mse = compute_MSE(y, pred)\n",
        "    pred_rmse = compute_RMSE(y, pred)\n",
        "    pred_nrmse = compute_NRMSE(y, pred)\n",
        "\n",
        "    return (original_psnr, original_ssim, original_mse, original_rmse, original_nrmse), (pred_psnr, pred_ssim, pred_mse, pred_rmse, pred_nrmse)\n",
        "\n",
        "def compute_MSE(img1, img2):\n",
        "    return skmetrics.mean_squared_error(img1, img2)\n",
        "\n",
        "\n",
        "def compute_RMSE(img1, img2):\n",
        "    return np.sqrt(compute_MSE(img1, img2))\n",
        "\n",
        "def compute_NRMSE(img1, img2):\n",
        "    return skmetrics.normalized_root_mse(img1, img2)\n",
        "\n",
        "def compute_PSNR(img1, img2, data_range = None):\n",
        "    return skmetrics.peak_signal_noise_ratio(img1, img2)\n",
        "\n",
        "\n",
        "def compute_SSIM(img1, img2, data_range = None, window_size=11, channel=1, size_average=True):\n",
        "\n",
        "    img1 = np.reshape(img1, [-1, 256, 256])\n",
        "    img2 = np.reshape(img2, [-1, 256, 256])\n",
        "\n",
        "\n",
        "    total_ssim = 0\n",
        "\n",
        "    for i in range(len(img1)):\n",
        "      try:\n",
        "        total_ssim += skmetrics.structural_similarity(img1[i], img2[i])\n",
        "      except:\n",
        "        pdb.set_trace()\n",
        "    \n",
        "    return total_ssim / len(img1)\n",
        "    \n",
        "\n",
        "def save_fig(x, y, pred, fig_name, original_result, pred_result, save_path = \"/content/\"):\n",
        "    # x, y, pred = x.numpy(), y.numpy(), pred.numpy()\n",
        "    f, ax = plt.subplots(1, 3, figsize=(30, 10))\n",
        "    ax[0].imshow(np.squeeze(x[0]), cmap=plt.cm.gray)\n",
        "    ax[0].set_title('Quarter-dose', fontsize=30)\n",
        "    ax[0].set_xlabel(\"PSNR: {:.4f}\\nSSIM: {:.4f}\\nMSE: {:.4f}\\nRMSE: {:.4f}\\nNRMSE: {:.4f}\".format(original_result[0],\n",
        "                                                                        original_result[1],\n",
        "                                                                        original_result[2],\n",
        "                                                                        original_result[3],\n",
        "                                                                        original_result[4]), fontsize=20)\n",
        "    # Predictions === \\nPSNR avg: {:.4f} \\nSSIM avg: {:.4f} \\nMSE avg: {:.4f} \\nRMSE avg: {:.4f} \\nNRMSE avg: {:.4f}\n",
        "    ax[1].imshow(np.squeeze(pred[0]), cmap=plt.cm.gray)\n",
        "    ax[1].set_title('Result', fontsize=30)\n",
        "    ax[1].set_xlabel(\"PSNR: {:.4f}\\nSSIM: {:.4f}\\nMSE: {:.4f}\\nRMSE: {:.4f}\\nNRMSE: {:.4f}\".format(pred_result[0],\n",
        "                                                                        pred_result[1],\n",
        "                                                                        pred_result[2],\n",
        "                                                                        pred_result[3],\n",
        "                                                                        pred_result[4]), fontsize=20)\n",
        "    ax[2].imshow(np.squeeze(y[0]), cmap=plt.cm.gray)\n",
        "    ax[2].set_title('Full-dose', fontsize=30)\n",
        "\n",
        "    f.savefig(os.path.join(save_path, 'result_{}.png'.format(fig_name)))\n",
        "    plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jiuv2HCDU5T7"
      },
      "source": [
        "def hybrid_loss(out, targets, criterion, percep_loss, metrics, weight = 0.6):\n",
        "\n",
        "  out_3d = out.repeat(1, 3, 1, 1)\n",
        "  targets_3d = targets.repeat(1, 3, 1, 1)\n",
        "  perceptual = percep_loss.forward(out_3d, targets_3d)\n",
        "  perceptual = torch.mean(perceptual)\n",
        "\n",
        "  l_loss = criterion(out, targets)\n",
        "\n",
        "  loss = l_loss + weight * perceptual\n",
        "\n",
        "  # metrics['loss'] += loss.data.cpu().numpy() * targets.size(0)\n",
        "  \n",
        "  return loss\n",
        "\n",
        "def vae_loss(out, targets, mu, logvar, criterion, percep_loss, metrics, hybrid = False, kld_weight = 1.0):\n",
        "\n",
        "  # pdb.set_trace()\n",
        "  \n",
        "  kld_loss = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "  \n",
        "  if hybrid:\n",
        "    mse_loss = hybrid_loss(out, targets, criterion, percep_loss, metrics)\n",
        "  else:\n",
        "    mse_loss = criterion(out, targets)\n",
        "  \n",
        "  loss = mse_loss + kld_weight * kld_loss\n",
        "\n",
        "  metrics['loss'] += loss.data.cpu().numpy() * targets.size(0)\n",
        "  \n",
        "  return loss\n",
        "\n",
        "def calc_loss(out, targets, criterion, percep_loss, metrics, perceptual = False):\n",
        "\n",
        "  if perceptual:\n",
        "      out_3d = out.repeat(1, 3, 1, 1)\n",
        "      targets_3d = targets.repeat(1, 3, 1, 1)\n",
        "      loss = percep_loss.forward(out_3d, targets_3d)\n",
        "      # loss = percep_loss.forward(out, targets)\n",
        "      loss = torch.mean(loss)\n",
        "      # pdb.set_trace()\n",
        "  else:\n",
        "    loss = criterion(out, targets)\n",
        "\n",
        "  metrics['loss'] += loss.data.cpu().numpy() * targets.size(0)\n",
        "  \n",
        "  return loss\n",
        "\n",
        "def print_metrics(metrics, epoch_samples, phase):\n",
        "  outputs = []\n",
        "  for k in metrics.keys():\n",
        "      outputs.append(\"{}: {:4f}\".format(k, metrics[k] / epoch_samples))\n",
        "\n",
        "  print(\"{}: {}\".format(phase, \", \".join(outputs)))\n",
        "\n",
        "def train(model, dataloader, optimizer, criterion, percep_loss, scheduler, checkpoint_path, print_iters = 10, epochs = 15, hybrid = False, perceptual = False, vae = False):\n",
        "  best_loss = 1e10\n",
        "  train_losses = []\n",
        "  total_iters = 0\n",
        "  start_time = time.time()\n",
        "\n",
        "  for epoch in range(1, epochs):\n",
        "\n",
        "    # get CUDA space\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    for phase in ['train', 'test']:\n",
        "      \n",
        "      gc.collect()\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "      if phase == 'train':\n",
        "\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        metrics = defaultdict(float)\n",
        "        epoch_samples = 0.0\n",
        "\n",
        "      elif phase == 'test':\n",
        "        \n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "        \n",
        "        model.eval()\n",
        "      \n",
        "      if phase == 'train':\n",
        "\n",
        "        for i, (data) in enumerate(dataloader[phase]):\n",
        "\n",
        "          inputs, targets = data\n",
        "          inputs, targets = inputs.to(device=device, dtype=torch.float), targets.to(device=device, dtype=torch.float)\n",
        "\n",
        "          if vae:\n",
        "            out, mu, logvar = model(inputs)\n",
        "          else:\n",
        "            out = model(inputs)\n",
        "\n",
        "          model.zero_grad()\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          if vae:\n",
        "            loss = vae_loss(out, targets, mu, logvar, criterion, percep_loss, metrics, hybrid = hybrid)\n",
        "          elif hybrid:\n",
        "            loss = hybrid_loss(out, targets, criterion, percep_loss, metrics)\n",
        "          else:\n",
        "            loss = calc_loss(out, targets, criterion, percep_loss, metrics, perceptual = perceptual)\n",
        "          \n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          epoch_loss = loss.item()\n",
        "          train_losses.append(epoch_loss)\n",
        "\n",
        "          # print\n",
        "          if i % print_iters == 0:\n",
        "              print(\"STEP [{}], EPOCH [{}/{}], ITER [{}/{}] \\nLOSS: {:.8f}, TIME: {:.1f}s\".format(i, epoch, \n",
        "                                                                                                  epochs, i+1, \n",
        "                                                                                                  len(dataloader[phase]), loss.item(), \n",
        "                                                                                                time.time() - start_time))\n",
        "          epoch_samples += len(inputs)\n",
        "\n",
        "      else:\n",
        "        print(\"Testing\")\n",
        "        # add testing code later if needed\n",
        "        # test(model)\n",
        "\n",
        "    print_metrics(metrics, epoch_samples, phase)\n",
        "    epoch_loss = metrics['loss'] / epoch_samples\n",
        "    \n",
        "    if phase == 'train':\n",
        "      scheduler.step()\n",
        "      for param_group in optimizer.param_groups:\n",
        "        print(\"LR\", param_group['lr'])\n",
        "\n",
        "    # save the model weights\n",
        "    if phase == 'test':\n",
        "        if epoch_loss < best_loss:\n",
        "          print(f\"saving best model to {checkpoint_path}\")\n",
        "          best_loss = epoch_loss\n",
        "          torch.save(model.state_dict(), checkpoint_path)\n",
        "        \n",
        "    \n",
        "  # load best model weights\n",
        "  model.load_state_dict(torch.load(checkpoint_path))\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWZKc1kgsgxO"
      },
      "source": [
        "def test(model, test_loader, mat_path, vae = False):\n",
        "      # load\n",
        "      model.eval()\n",
        "\n",
        "      # compute PSNR, SSIM, RMSE\n",
        "      ori_psnr_avg, ori_ssim_avg, ori_mse_avg, ori_rmse_avg, ori_nrmse_avg = 0, 0, 0, 0, 0\n",
        "      pred_psnr_avg, pred_ssim_avg, pred_mse_avg, pred_rmse_avg, pred_nrmse_avg= 0, 0, 0, 0, 0\n",
        "\n",
        "      with torch.no_grad():\n",
        "          for i, (x,y) in enumerate(test_loader):\n",
        "\n",
        "              x, y = x.to(device=device, dtype=torch.float), y.to(device=device, dtype=torch.float)\n",
        "\n",
        "              shape_ = x.shape[-1]\n",
        "\n",
        "              if vae:\n",
        "                pred, _, _ = model(x)\n",
        "              else:\n",
        "                pred = model(x)\n",
        "\n",
        "              x = x.cpu().detach().numpy()\n",
        "              y = y.cpu().detach().numpy()\n",
        "              pred = pred.cpu().detach().numpy()\n",
        "\n",
        "              # x = np.squeeze(x)\n",
        "              # y = np.squeeze(y)\n",
        "              # pred = np.squeeze(pred)\n",
        "\n",
        "              original_result, pred_result = compute_measure(x, y, pred)\n",
        "              \n",
        "              ori_psnr_avg += original_result[0]\n",
        "              ori_ssim_avg += original_result[1]\n",
        "              ori_mse_avg += original_result[2]\n",
        "              ori_rmse_avg += original_result[3]\n",
        "              ori_nrmse_avg += original_result[4]\n",
        "\n",
        "              pred_psnr_avg += pred_result[0]\n",
        "              pred_ssim_avg += pred_result[1]\n",
        "              pred_mse_avg += pred_result[2]\n",
        "              pred_rmse_avg += pred_result[3]\n",
        "              pred_nrmse_avg += pred_result[4]\n",
        "\n",
        "              # def save_fig(self, x, y, pred, fig_name, original_result, pred_result):\n",
        "\n",
        "\n",
        "              save_fig(x, y, pred, i, original_result, pred_result)\n",
        "\n",
        "          print('\\n')\n",
        "          print('Original === \\nPSNR avg: {:.4f} \\nSSIM avg: {:.4f} \\nMSE avg: {:.4f} \\nRMSE avg: {:.4f} \\nNRMSE avg: {:.4f}'.format(ori_psnr_avg/len(test_loader), \n",
        "                                                                                          ori_ssim_avg/len(test_loader), \n",
        "                                                                                          ori_mse_avg/len(test_loader),\n",
        "                                                                                          ori_rmse_avg/len(test_loader),\n",
        "                                                                                          ori_nrmse_avg/len(test_loader)\n",
        "                                                                                          ))\n",
        "          print('\\n')\n",
        "          print('Predictions === \\nPSNR avg: {:.4f} \\nSSIM avg: {:.4f} \\nMSE avg: {:.4f} \\nRMSE avg: {:.4f} \\nNRMSE avg: {:.4f}'.format(pred_psnr_avg/len(test_loader), \n",
        "                                                                                                pred_ssim_avg/len(test_loader), \n",
        "                                                                                                pred_mse_avg/len(test_loader),\n",
        "                                                                                                pred_rmse_avg/len(test_loader),\n",
        "                                                                                                pred_nrmse_avg/len(test_loader)\n",
        "                                                                                                ))\n",
        "          \n",
        "          sio.savemat(mat_path, {'psnr': pred_psnr_avg/len(test_loader),\n",
        "                                 'ssim': pred_ssim_avg/len(test_loader),\n",
        "                                 'mse': pred_mse_avg/len(test_loader),\n",
        "                                 'rmse': pred_rmse_avg/len(test_loader),\n",
        "                                 'nrsme': pred_nrmse_avg/len(test_loader)})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zelyBaHm7fkP"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbPeEBgp1JfJ"
      },
      "source": [
        "transform = transforms.Compose([\n",
        "  transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "nw_train_dataset = CT_Dataset(inputs = ld_train, targets = ld_train_nw, transform = transform)\n",
        "nw_test_dataset = CT_Dataset(inputs = ld_test, targets = ld_test_nw, transform = transform)\n",
        "\n",
        "nw_train_loader = DataLoader(dataset = nw_train_dataset, batch_size = 10, shuffle = True, num_workers=0)\n",
        "nw_test_loader = DataLoader(dataset = nw_test_dataset, batch_size = 10, shuffle = True, num_workers=0)\n",
        "\n",
        "nw_dataloader = {\n",
        "    'train': nw_train_loader,\n",
        "    'test': nw_test_loader\n",
        "}\n",
        "\n",
        "print(len(nw_dataloader['train']), len(nw_dataloader['test']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3Q0ednuaz5I"
      },
      "source": [
        "transform = transforms.Compose([\n",
        "  transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# n = 250 \n",
        "# indices = np.random.choice(ld_train.shape[0], n, replace=False)  \n",
        "\n",
        "# ld_train = ld_train[indices]\n",
        "# fd_train = fd_train[indices]\n",
        "\n",
        "train_dataset = CT_Dataset(inputs = ld_train, targets = fd_train, transform = transform)\n",
        "test_dataset = CT_Dataset(inputs = ld_test, targets = fd_test, transform = transform)\n",
        "\n",
        "train_loader = DataLoader(dataset = train_dataset, batch_size = 10, shuffle = True, num_workers= 0)\n",
        "test_loader = DataLoader(dataset = test_dataset, batch_size = 10, shuffle = False, num_workers= 0)\n",
        "\n",
        "dataloader = {\n",
        "    'train': train_loader,\n",
        "    'test': test_loader\n",
        "}\n",
        "\n",
        "print(len(dataloader['train']), len(dataloader['test']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-fUuI6x8KhI"
      },
      "source": [
        "## Start Training\n",
        "\n",
        "Uncomment the following code for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "va2ndAVGVF-8"
      },
      "source": [
        "# gc.collect()\n",
        "# torch.cuda.empty_cache()\n",
        "\n",
        "# #pretext_downstream\n",
        "# save_path = \"/content/save_path\"\n",
        "# mat_path = save_path + \".mat\"\n",
        "# checkpoint_path = save_path + \".pth\"\n",
        "\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# model = SSWL_IDN().to(device)\n",
        "# vae_bool = True\n",
        "\n",
        "# lr = 1e-5\n",
        "# epochs = 15\n",
        "# criterion = nn.MSELoss()\n",
        "# loss_fn = lpips.LPIPS(net='vgg')\n",
        "# loss_fn.cuda()\n",
        "\n",
        "# optimizer_ = optimizer = optim.Adam(model.parameters(), lr)\n",
        "# scheduler = lr_scheduler.StepLR(optimizer, step_size=8, gamma=0.1)\n",
        "\n",
        "# summary(model, input_size=(1, 256, 256))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8PEVrnbVHbM"
      },
      "source": [
        "# # SSWL Training\n",
        "# model = train(model, nw_dataloader, optimizer, criterion, loss_fn, scheduler, checkpoint_path, print_iters = 1, epochs = epochs, perceptual = False, hybrid = True, vae = vae_bool)\n",
        "# # Denoising Training\n",
        "# model = train(model, dataloader, optimizer, criterion, loss_fn, scheduler, checkpoint_path, print_iters = 1, epochs = epochs, perceptual = False, hybrid = True, vae = vae_bool)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTwP5BlD8Ovh"
      },
      "source": [
        "# Evaluate\n",
        "\n",
        "To test the code, load the provided pth file after instantiating the model. Then, run the test code and receive a prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_RZBt4r8Elk"
      },
      "source": [
        "model.load_state_dict(torch.load(checkpoint_path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkgaVbWXwN98"
      },
      "source": [
        "# visualize predictions\n",
        "\n",
        "model.eval() \n",
        "\n",
        "pred_masks = []\n",
        "inputs_arr = []\n",
        "targets_arr = []\n",
        "\n",
        "with torch.no_grad():\n",
        "  print(\"starting validation\")\n",
        "  for inputs, targets in dataloader['test']:\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    inputs = inputs.to(device=device, dtype=torch.float)\n",
        "    targets = targets.to(device=device, dtype=torch.float)\n",
        "    if vae_bool:\n",
        "      pred, _, _ = model(inputs)\n",
        "    else:\n",
        "      pred = model(inputs)\n",
        "    pred = pred.data.cpu().numpy()\n",
        "    inputs_np = inputs.data.cpu().numpy()\n",
        "    targets_np = targets.data.cpu().numpy()\n",
        "    for i in range (len(pred)):\n",
        "      inputs_arr.append(inputs_np[i])\n",
        "      targets_arr.append(targets_np[i])\n",
        "      pred_masks.append(pred[i])\n",
        "\n",
        "inputs_arr = np.reshape(inputs_arr, [-1, 256, 256, 1])\n",
        "targets_arr = np.reshape(targets_arr, [-1, 256, 256, 1])\n",
        "pred_masks = np.reshape(pred_masks, [-1, 256, 256, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koG6nU0s4tb7"
      },
      "source": [
        "test(model, dataloader['test'], mat_path, vae = vae_bool)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}